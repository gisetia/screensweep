import re
import os
import pandas as pd
import numpy as np
from math import log10
from typing import Tuple, Optional

from .utils import timer

pd.options.mode.chained_assignment = None


@timer
def get_sweep_data(data_dir: str, params: dict) -> pd.DataFrame:
    '''Get dataframe with all data resulting from a double parameter sweep of
    'screen-analyzer analyze'.

    Dataframe example:

    gene_name	low_counts	high_counts	    p	    p_fdr	    log2_mi
    A1BG	    1	        0	            1.0	    1.03441	    0.049043

    start	    end	        srt_pos	    end_pos	    srt_off	    end_off
    tx-2000	    tx-9500	    tx	        tx	        -2000	    -9500

    Arguments:
    data_dir: str eg. 'data/screen-analyzer-data'

    params: dict eg {'screen_name': 'PDL1_IFNg',
                     'assembly': 'hg38',
                     'trim_length': '50',
                     'mode': 'collapse',
                     'start': 'tx',
                     'end': 'tx',
                     'overlap': 'both',
                     'direction': 'sense',
                     'step': 500}
    '''

    data_path = (f'''{data_dir}/{params['screen_name']}/'''
                 f'''{params['assembly']}/{params['trim_length']}/'''
                 f'''mode={params['mode']}_direction={params['direction']}'''
                 f'''_overlap={params['overlap']}/double-sweep'''
                 f'''_step={params['step']}/''')

    files = os.listdir(data_path)
    df_list = []  # Initialize list to append data
    repeated_genes = set()
    for idx, filename in enumerate(files):

        if filename.startswith('out'):

            # print(f'Reading file: {idx + 1} of {len(files)}')

            # Get param values from filename
            match = re.search(r'_start=(.*?)_', filename)
            start = match.group(1)
            match = re.search(r'_end=(.*?)_', filename)
            end = match.group(1)

            # File to df, add columns for each param value and add to list
            df = pd.read_csv(data_path + filename, sep='\t',
                             index_col=None, header=None)
            df[6] = start
            df[7] = end

            # Remove header line if included
            if df.iloc[0][0] == 'gene':
                df = df.drop([0])

            df = df.rename(columns={0: 'gene_name', 1: 'low_counts',
                                    2: 'high_counts', 3: 'p',
                                    4: 'p_fdr', 5: 'log2_mi',
                                    6: 'start', 7: 'end'})

            repeated = df.groupby('gene_name').apply(lambda x: len(x))
            repeated_genes.update(repeated[repeated > 1].index)

            df = df.groupby('gene_name').first()
            df = df.reset_index()

            df_list.append(df)

    if repeated_genes:
        print('-- Warning! The following genes were repeated, so only first '
              'instance was considered:')
        print('\n'.join(repeated_genes))

    # Create single dataframe from list
    sweep_data = pd.concat(df_list, axis=0, ignore_index=True)

    # sweep_data = sweep_data.rename(columns={0: 'gene_name', 1: 'low_counts',
    #                                         2: 'high_counts', 3: 'p',
    #                                         4: 'p_fdr', 5: 'log2_mi',
    #                                         6: 'start', 7: 'end'})

    # Trandform parameter into numbers, eg. 'tx-100' is changed to column
    # 'offset' with value -100:int
    sweep_data[['srt_off', 'end_off']] = sweep_data[['start', 'end']].applymap(
        lambda x: ''.join(re.split('(-|\\+)', x)[1:3])).astype(np.int16)

    # Rearrange and change data types
    sweep_data = sweep_data.sort_values(by=['gene_name', 'srt_off', 'end_off'])
    sweep_data = sweep_data.drop(['start', 'end'], axis=1)

    int_cols = ['low_counts', 'high_counts', 'srt_off', 'end_off']
    sweep_data[int_cols] = (sweep_data[int_cols]
                            .apply(lambda x:
                                   pd.to_numeric(x, downcast='integer')))

    float_cols = ['p', 'p_fdr', 'log2_mi']
    sweep_data[float_cols] = (sweep_data[float_cols]
                              .apply(lambda x:
                                     pd.to_numeric(x, downcast='float')))

    return sweep_data


@ timer
def write_sweep_data(data_dir: str, sweep_data: pd.DataFrame,
                     params: dict) -> pd.DataFrame:
    '''Writes compressed file containing all data from dataframe
    'sweep_data' generated by 'get_sweep_data' plus 4 additional columns that
    include data on how log2_mi and p_fdr change as parameters 'start' and
    'end' vary. Returns dataframe with this info.

    The 4 new columns are: 'sl_sdir', 'sl_edir', 'p_min_sdir', 'p_min_edir'

    'sl_sdir' and 'sl_edir' represent the change in log2_mi when changing
    the start parameter ('sdir': start direction) or the end parameter
    ('edir': end direction) by 1,000 bp. Ie.
    ((log2_mi at param i+1) - (log2_mi at param i)) / (step size in bp * 0.001)

    'p_min_sdir' and 'p_min_edir' contain the minimum pfdr-value between
    consecutive parameters in both start and end directions.
    '''

    gene_info = dict()
    grouped = sweep_data.groupby('gene_name')
    for name, group in grouped:

        print(name)

        gene_data = group.pivot(index='srt_off', columns='end_off',
                                values=['gene_name', 'low_counts',
                                        'high_counts', 'p', 'p_fdr',
                                        'log2_mi'])

        # Get slopes of log2 MI when changing parameters in both directions
        # (delta log2 MI per 1,000 bp)
        slope_sdir = (gene_data['log2_mi']
                      - gene_data['log2_mi'].shift(1))/(params['step']*0.001)
        slope_edir = (gene_data['log2_mi']
                      - gene_data['log2_mi'].shift(1,
                                                   axis=1))/(params['step']
                                                             * 0.001)

        # Get minimum p-value between consecutive parameters in both start
        # and end directions
        shift_sdir = gene_data['p_fdr'].shift(1)
        shift_sdir.columns = pd.MultiIndex.from_arrays(
            [tuple('p_shift_sdir' for x in shift_sdir.columns),
             tuple(x for x in shift_sdir.columns)])
        gene_data = pd.concat([gene_data, shift_sdir], ignore_index=False,
                              axis=1)

        shift_edir = gene_data['p_fdr'].shift(1, axis=1)
        shift_edir.columns = pd.MultiIndex.from_arrays(
            [tuple('p_shift_edir' for x in shift_edir.columns),
             tuple(x for x in shift_edir.columns)])
        gene_data = pd.concat([gene_data, shift_edir], ignore_index=False,
                              axis=1)

        # Stack data and add columns
        gene_data = gene_data.stack()

        gene_data['p_min_sdir'] = gene_data[['p_fdr',
                                             'p_shift_sdir']].min(axis=1)
        gene_data['p_min_edir'] = gene_data[['p_fdr',
                                             'p_shift_edir']].min(axis=1)
        gene_data = gene_data.drop(columns=['p_shift_sdir', 'p_shift_edir'])

        gene_data['sl_sdir'] = slope_sdir.stack()
        gene_data['sl_edir'] = slope_edir.stack()

        gene_data = gene_data[gene_data.gene_name.notnull()]

        gene_info[name] = gene_data

    all_info = pd.concat(gene_info.values(), ignore_index=False)

    int_cols = ['low_counts', 'high_counts']
    all_info[int_cols] = (all_info[int_cols]
                          .apply(lambda x:
                                 pd.to_numeric(x, downcast='integer')))
    float_cols = ['p', 'p_fdr', 'log2_mi', 'sl_sdir', 'sl_edir']
    all_info[float_cols] = (all_info[float_cols]
                            .apply(lambda x:
                                   pd.to_numeric(x, downcast='float')))

    # all_info.to_csv(f'{data_path}all_gene_info_csv.gz',
    #                 compression='gzip')
    data_path = (f'''{data_dir}/{params['screen_name']}/'''
                 f'''{params['assembly']}/{params['trim_length']}/'''
                 f'''mode={params['mode']}_direction={params['direction']}'''
                 f'''_overlap={params['overlap']}/double-sweep'''
                 f'''_step={params['step']}/''')

    if not os.path.exists(data_path):
        os.makedirs(data_path)
        print('Creating analyzed directory.')

    print(f'Writing sweep data for screen {params["screen_name"]}')
    all_info.to_parquet(f'{data_path}all_gene_info.parquet.snappy',
                        engine='pyarrow', compression='snappy')

    return all_info


# @timer
def read_analyzed_sweep(data_dir: str,
                        params: dict) -> \
        pd.core.groupby.generic.DataFrameGroupBy:
    '''Reads compressed file created by 'write_sweep_data' containing
    the all data from sweeping the start and end paramenters with the
    screen-analyzer. Returns pandas dataframe grouped by gene name.

    data_dir: str eg. 'data/analyzed-data'
    params: dict eg {'screen_name': 'PDL1_IFNg',
                     'assembly': 'hg38',
                     'trim_length': '50',
                     'mode': 'collapse',
                     'start': 'tx',
                     'end': 'tx',
                     'overlap': 'both',
                     'direction': 'sense',
                     'step': 500}
    '''

    data_file = (f'''{data_dir}/{params['screen_name']}/'''
                 f'''{params['assembly']}/{params['trim_length']}/'''
                 f'''mode={params['mode']}_direction={params['direction']}'''
                 f'''_overlap={params['overlap']}/double-sweep'''
                 f'''_step={params['step']}/all_gene_info''')

    # sweep = pd.read_csv(f'{data_file}_csv.gz', compression='gzip')
    sweep = pd.read_parquet(f'{data_file}.parquet.snappy',
                            engine='pyarrow')

    # sweep = sweep.set_index(keys=['srt_off', 'end_off'])
    grouped_sweep = sweep.groupby('gene_name')

    return grouped_sweep


def get_gene_info(gene: str,
                  grouped_sweep: pd.core.groupby.generic.DataFrameGroupBy) -> \
        pd.DataFrame:
    '''Given a grouped_sweep created by 'read_analyzed_sweep', returns
    unstacked dataframe containing all sweep data for a given gene.
    '''
    # gene = gene.upper()
    gene_info = grouped_sweep.get_group(gene)

    return gene_info.unstack()


# @ timer
def flag_by_slope(grouped_sweep: pd.core.groupby.generic.DataFrameGroupBy,
                  p_thr: float,
                  slope_thr: float,
                  ) -> pd.DataFrame:
    ''' need to update
    Given a grouped_sweep created by 'read_analyzed_sweep', finds genes
    that have a higher slope and p ratio than the thresholds given by
    'slope_thr' and 'p_thr'.
    Slope refers to the change in the log2 mutation index per 1,000 bp.
    Returns tuple with two dictionaries, where keys are gene names and values
    are subsets of dataframe where both thresholds are passed when changing
    either the start or the end parameter, respectively.
    '''

    flagged_df_list = []
    ct = 0

    for name, group in grouped_sweep:

        # Continue if at least one point in sweep is highly significant
        if not group.query('p < @p_thr').empty:

            flags_sdir = group.query(flags_query('start'))
            flags_edir = group.query(flags_query('end'))

            # Remove flags that fall in regions outside of genes and those
            # where a smaller part of the gene results in a p-value lower
            # than p_thr
            if not flags_sdir.empty:
                flags_sdir = flags_sdir.reset_index().query('srt_off > 0 '
                                                            '& end_off <= 0'
                                                            '& p < @p_thr')
            if not flags_edir.empty:
                flags_edir = flags_edir.reset_index().query('srt_off >= 0 '
                                                            '& end_off <= 0')

                # Remove flags where going into the gene results in a p-value
                # lower than p_thr (trickier than for sdir since the previous
                # p-value is not saved in flags_edir, so you have to look it
                # up in the group)
                step = abs(group.reset_index()['end_off'].iloc[1]
                           - group.reset_index()['end_off'].iloc[0])
                flags_edir['prev_end_off'] = flags_edir['end_off'] - step
                flags_edir = flags_edir.set_index(['srt_off', 'prev_end_off'])
                flags_edir = flags_edir[group.loc[flags_edir.index].p
                                        < p_thr]

            if not flags_sdir.empty or not flags_edir.empty:
                ct += 1
                # print(f'Flagged: {name}')

                try:
                    mi_at_tx = group.loc[0, 0].log2_mi
                    p_at_tx = group.loc[0, 0].p
                except KeyError:
                    mi_at_tx = np.nan
                    p_at_tx = np.nan

                df = pd.Series({'gene': name,
                                'mi_at_tx': mi_at_tx,
                                'p_at_tx': p_at_tx})

                flagged_df_list.append(df)

    print(f'# flagged genes: {ct}')

    if flagged_df_list:
        flagged = pd.concat(flagged_df_list, axis=1).T
        flagged = flagged.iloc[abs(flagged.mi_at_tx).sort_values().index]
        flagged.mi_at_tx = flagged.mi_at_tx.astype(float).round(2)
        flagged.p_at_tx = flagged.p_at_tx.astype(float).apply(lambda x:
                                                              f'{x:.2e}')
    else:
        flagged = pd.DataFrame(columns=['gene', 'mi_at_tx', 'p_at_tx'])

    flagged = flagged.reset_index(drop=True)
    # print('\nLikely already seen:')
    # print("\n".join(already))

    return flagged


def get_flags_for_gene(gene: str,
                       grouped_sweep: pd.core.groupby.generic.DataFrameGroupBy,
                       p_thr: Optional[float] = None,
                       slope_thr: Optional[float] = None,
                       p_ratio_thr: Optional[float] = None) -> Tuple[
        pd.DataFrame, pd.DataFrame]:

    p_thr = p_thr or 0.001
    slope_thr = slope_thr or 2
    p_ratio_thr = p_ratio_thr or 20

    gene_info = get_gene_info(gene, grouped_sweep).stack()
    flags_sdir = pd.DataFrame()
    flags_edir = pd.DataFrame()
    if not gene_info.query('p_fdr < @p_thr').empty:
        flags_sdir = gene_info.query(flags_query('start'))
        flags_edir = gene_info.query(flags_query('end'))

    return (flags_sdir, flags_edir)


def flags_query(param: str) -> str:
    '''Return string to use for querying flagged genes. Param: 'start' or
    'end'.
    '''

    q = (f'abs(sl_{param[0]}dir) > @slope_thr '
         f'& p_min_{param[0]}dir < @p_thr')

    return q


def sort_optimized_mi(group, p_thr=1e-5, weight_mi=1, weight_p=1,
                      weight_ins=0, weight_off=0):

    opt = group.copy(deep=True)
    opt = opt.reset_index()

    # Remove out of gene and non significant regions
    opt = opt.query('srt_off >=0 & end_off <= 0 & p < @p_thr')

    # Get normalized values for log2_mi, p, ins number and offset
    opt['norm_mi'] = opt.log2_mi/10
    opt['norm_log10_p'] = opt.p.apply(
        lambda x: abs(-log10(x))/50 if x > 0 else 1)
    max_ins = max(opt.high_counts + opt.low_counts)
    opt['norm_ins'] = (opt.high_counts + opt.low_counts)/max_ins

    max_off = max(abs(opt.srt_off) + abs(opt.end_off))
    opt['norm_off'] = 1 - (abs(opt.srt_off) + abs(opt.end_off))/max_off

    # Get score based on normalized values and weighs
    opt['score'] = ((weight_mi*opt.norm_mi)**2
                    + (weight_p*opt.norm_log10_p)**2
                    + (weight_ins*opt.norm_ins)**2
                    + (weight_off*opt.norm_off)**2)

    # Sort by score
    opt = opt.sort_values(by=['score'], ascending=False)

    opt = opt[['srt_off', 'end_off', 'gene_name', 'high_counts',
               'low_counts', 'log2_mi', 'p', 'score', 'norm_mi',
               'norm_log10_p', 'norm_ins', 'norm_off']]

    return opt


def optimize_flagged_genes(flagged, grouped_sweep, delta_mi_thr=0,
                           p_thr=1e-5, weight_mi=2, weight_p=1,
                           weight_ins=0, weight_off=0):
    opt_list = []
    for gene in list(flagged.gene):

        group = grouped_sweep.get_group(gene)
        opt = sort_optimized_mi(group, p_thr, weight_mi, weight_p,
                                weight_ins, weight_off)

        gene_at_tx = flagged.set_index('gene').loc[gene]
        gene_at_tx['high_at_tx'] = group.loc[0, 0]['high_counts']
        gene_at_tx['low_at_tx'] = group.loc[0, 0]['low_counts']
        gene_at_tx['counts_at_tx'] = (gene_at_tx.high_at_tx
                                      + gene_at_tx.low_at_tx)

        gene_opt = gene_at_tx.append(opt.iloc[0][['gene_name', 'srt_off',
                                                  'end_off', 'log2_mi', 'p',
                                                  'low_counts',
                                                  'high_counts']])
        gene_opt['counts'] = gene_opt.high_counts + gene_opt.low_counts

        if gene_opt.srt_off != 0 or gene_opt.end_off != 0:
            if abs(gene_opt.mi_at_tx - gene_opt.log2_mi) > delta_mi_thr:
                opt_list.append(gene_opt)

    optimized_mi = pd.concat(opt_list, axis=1).T

    return optimized_mi
